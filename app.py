# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PzBSvQdqGwuAGxsEQ3hRNeqtHOwrS9zT
"""

import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.vectorstores import FAISS
from langchain_community.embeddings import OllamaEmbeddings
from transformers import pipeline
from langchain_community.llms import Ollama
from colabcode import ColabCode

@st.cache_resource
# Load the Vector store
def load_vectorstore():
    embedding_model = OllamaEmbeddings(model="nomic-embed-text")
    db = FAISS.load_local("faiss_index", embedding_model, allow_dangerous_deserialization=True)
    return db
db = load_vectorstore()

# load the transformer which will be used to rewrite the query
def load_rewriter():
  return pipeline("text2text-generation", model="google/flan-t5-base")

# rewrite the query
def rewrite_query(query):
    rewriter = load_rewriter()
    prompt = f"""
    Rewrite the following user question into a clear, formal, regulation-compliant query suitable for searching a building code database.

    Original Query: {query}

    Rephrased Query:
    """
    clean_query = rewriter(prompt, max_length=64, do_sample=False)[0]["generated_text"]
    return clean_query.strip()

llm = Ollama(model='llama3.2') # using this as my llm to generate answers

# use the rewritten query + context (most relevant docs) to generate a final answer
def generate_response(clean_query,context):
    final_prompt = f"""
    You are a building regulations expert in Ontario.

    Question: {clean_query}

    Relevant Regulation Information:
    {context}

    Answer the user query based on the relevant regulation information.

    """
    return llm.invoke(final_prompt)


#Stremlit UI
st.set_page_config(page_title="Permit Code Validator", page_icon="📘")
st.title("🏗️ Ontario Building Code Validator")

query = st.text_input("Ask a building code question:", placeholder="e.g. Do telescopic bleachers need locking devices?") # user inputs the query here

if query:
  with st.spinner("🔍 Rephrasing and searching..."):
      rephrased = rewrite_query(query) # retunrs cleaned and better query
      st.subheader("🔎 Rephrased Query")
      st.write(rephrased) # To see how better the use query has been rephrased.
      results = db.similarity_search(rephrased, k=4)
      context = "\n\n".join([doc.page_content for doc in results])

  with st.spinner("🧠 Generating expert response..."):
      answer = generate_response(rephrased, context)

  st.subheader("📌 Final Answer")
  st.write(answer)

  st.subheader("🔎 Retrieved Context")
  for i, doc in enumerate(results):
      st.markdown(f"**Chunk {i+1}:**\n{doc.page_content[:500]}...")

